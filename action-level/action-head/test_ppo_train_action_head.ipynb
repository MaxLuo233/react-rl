{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzq/miniconda3/envs/react-rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Load Data Done-----\n"
     ]
    }
   ],
   "source": [
    "from react_env import ReActEnv\n",
    "# from react_env import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import accelerate\n",
    "\n",
    "\n",
    "def load_data(react_file_path, cache_path, cluster_path):\n",
    "    with open(react_file_path,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    react_data = []\n",
    "    for line in lines:\n",
    "        line = json.loads(line)\n",
    "        react_data.append(line)\n",
    "    with open(cache_path,'rb') as f:\n",
    "        dict_action_embedding = pickle.load(f)\n",
    "    with open(cluster_path,'r') as f:\n",
    "        dict_action_cluster_label = json.loads(f.read())\n",
    "    return react_data, dict_action_embedding, dict_action_cluster_label\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "react_file_path = \"/home/lzq/react-rl/action-level/action-head/react_prompt/new_react_prompt.jsonl\"\n",
    "cache_path = \"embedding_cache.pkl\"\n",
    "cluster_path = \"cluster_actions.json\"\n",
    "list_react_data, dict_action_embedding, dict_action_cluster_label = load_data(react_file_path, cache_path, cluster_path)\n",
    "dict_label_embedding = {}\n",
    "for action in list(dict_action_embedding.keys()):\n",
    "    if dict_action_cluster_label[action] not in dict_label_embedding:\n",
    "        dict_label_embedding[dict_action_cluster_label[action]] = []\n",
    "    else:\n",
    "        dict_label_embedding[dict_action_cluster_label[action]].append(dict_action_embedding[action])\n",
    "for label in list(dict_label_embedding.keys()):\n",
    "    dict_label_embedding[label] = np.mean(np.array(dict_label_embedding[label]),axis=0)\n",
    "print(\"-----Load Data Done-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Load Model Done-----\n"
     ]
    }
   ],
   "source": [
    "from mistral_with_ppo_head import MistralPPOHeadModel\n",
    "from transformers import LlamaTokenizerFast, AutoTokenizer, AutoModelForCausalLM, MistralConfig\n",
    "from ppo_head import PPOHead\n",
    "\n",
    "model_path = \"/share/huggingface/hub/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24/\"\n",
    "config = MistralConfig.from_pretrained(model_path)\n",
    "\n",
    "agent_model = MistralPPOHeadModel(config=config)#, MistralPPOHeadModel(config=config)\n",
    "agent_model_embedding_layer = agent_model.model.embed_tokens\n",
    "embedding_dim = agent_model.model.embed_tokens.embedding_dim\n",
    "# value_model.set_action_head(PPOHead(input_dim=embedding_dim, output_dim=1))\n",
    "\n",
    "agent_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "agent_model = agent_model.from_pretrained(model_path)\n",
    "\n",
    "if agent_tokenizer.pad_token is None:\n",
    "    agent_tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "    agent_model.resize_token_embeddings(len(agent_tokenizer))\n",
    "print(\"-----Load Model Done-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_episodes = 10\n",
    "num_steps = 8 # 20; 8 for toy test\n",
    "learning_rate = 1e-5\n",
    "# total_timesteps = 40\n",
    "num_envs = 2 # 256; 2 for toy test\n",
    "batch_size = num_steps * num_envs # 8*2 for toy test\n",
    "minibatch_size = 8 # 64; 8 for toy test\n",
    "anneal_lr = True\n",
    "\n",
    "gae = True\n",
    "gamma = 0.99\n",
    "gae_lambda = 0.95\n",
    "\n",
    "update_epochs = 3\n",
    "\n",
    "clip_coef = 0.2\n",
    "norm_adv = True\n",
    "clip_vloss = True\n",
    "ent_coef = 0.01\n",
    "vf_coef = 0.5\n",
    "max_grad_norm = 0.5\n",
    "target_kl = None\n",
    "# Initialize\n",
    "obs = []\n",
    "for i in range(num_steps):\n",
    "    obs.append(['']*num_envs)\n",
    "\n",
    "actions = torch.zeros((num_steps, num_envs)).to(device)\n",
    "logprobs = torch.zeros((num_steps, num_envs)).to(device)\n",
    "rewards = torch.zeros((num_steps, num_envs)).to(device)\n",
    "dones = torch.zeros((num_steps, num_envs)).to(device)\n",
    "values = torch.zeros((num_steps, num_envs)).to(device)\n",
    "# avg_returns = deque(maxlen=20)\n",
    "\n",
    "# start the game\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "num_updates = 20 # 40/8=5 for toy test\n",
    "\n",
    "update = 1\n",
    "# 构建环境列表\n",
    "envs = []\n",
    "embedding_initial_states = []\n",
    "list_inputs = []\n",
    "for react_data in list_react_data[(update-1)*num_envs:(update)*num_envs]:\n",
    "    env = ReActEnv(react_data, dict_action_embedding, dict_action_cluster_label, dict_label_embedding)\n",
    "    inputs = agent_tokenizer(env.state)\n",
    "    envs.append(env)\n",
    "\n",
    "next_obs = [''] * num_envs\n",
    "for env in envs:\n",
    "    index = envs.index(env)\n",
    "    next_obs[index] = env.state\n",
    "next_done = torch.zeros(num_envs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_model.set_action_head(PPOHead(input_dim=embedding_dim, output_dim=100)) # 先加载后set_action_head\n",
    "agent_model.cuda()\n",
    "# agent_model = nn.DataParallel(agent_model, device_ids =[0,1,2,3])\n",
    "\n",
    "optimizer = optim.Adam(agent_model.parameters(), lr=learning_rate, eps=1e-5)\n",
    "# Annealing the rate if instructed to do so.\n",
    "if anneal_lr:\n",
    "    frac = 1.0 - (update - 1.0) / num_updates\n",
    "    lrnow = frac * learning_rate\n",
    "    optimizer.param_groups[0][\"lr\"] = lrnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:00<00:01,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:00<00:01,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:01<00:01,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:01<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:01<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:01<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:', '\\n\\n\\n每个问题中，包含了故障告警和已进行的故障定位操作，格式如下：\\n\\nAlert:你要处理的告警信息\\nAction:你应该采取的行动\\nAction Input:行动的需要的具体参数，以JSON格式的Key-Value字典表示\\nThought:你应当解释采取所选行动的原因\\nObservation:行动中观察到的结果\\n... (上述Action/Action/Action Input/Thought/Observation可以重复多次，但Alert不会重复)\\n\\n问题列表：\\n\\nQuestion 1:\\n  Alert:虚拟机公网EIP不通\\n  Action:检查虚拟机是否配置IP地址\\n  Action Input:{\"cmd\": \"ifconfig -a\"}\\n  Thought:虚拟机要访问公网，应当具有IP地址，所以应当先检查是否正确配置了IP地址\\n  Observation:有IP地址\\n\\nQuestion 2:\\n  Alert:100002 微服务 Running 状态的容器数小于 1\\n  Action:']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(0, num_steps)): \n",
    "    global_step += 1\n",
    "    obs[step] = next_obs\n",
    "    dones[step] = next_done\n",
    "    # 执行action\n",
    "    with torch.no_grad():\n",
    "        print(next_obs)\n",
    "        encoded_inputs = agent_tokenizer(next_obs, padding=True, truncation=True, max_length=1024, return_tensors='pt')\n",
    "        encoded_inputs = encoded_inputs.to(device)\n",
    "        outputs = agent_model(**encoded_inputs) \n",
    "        logits = outputs.logits.squeeze(1) # 输出维度[batch_env_size, 1, prediction_size]\n",
    "        probs = Categorical(logits=logits)\n",
    "        action = probs.sample() # 多个环境同时采样\n",
    "        logprob = probs.log_prob(action)\n",
    "        # action = torch.max(logits.squeeze(1), dim=-1)\n",
    "        # value = value_model(**encoded_inputs)\n",
    "        # values[step] = value.flatten()\n",
    "    actions[step] = action\n",
    "    logprobs[step] = logprob\n",
    "    for i, env in enumerate(envs):\n",
    "        next_obs_, reward, done_, _ = env.step(action[i].cpu().item()) # 环境交互\n",
    "        rewards[step][i] = torch.tensor(reward).to(device).view(-1)\n",
    "        next_obs[i], next_done[i] = next_obs_, torch.tensor(done_).to(device)\n",
    "\n",
    "    with torch.no_grad(): # 不含value计算步骤，可省略\n",
    "        if gae:\n",
    "            advantages = torch.zeros_like(rewards).to(device)\n",
    "            lastgaelam = 0\n",
    "            for t in reversed(range(num_steps)):\n",
    "                if t == num_steps - 1:\n",
    "                    nextnonterminal = 1.0 - next_done\n",
    "                else:\n",
    "                    nextnonterminal = 1.0 - dones[t + 1]\n",
    "                delta = rewards[t]\n",
    "                advantages[t] = lastgaelam = delta + gamma * gae_lambda * nextnonterminal * lastgaelam\n",
    "            returns = advantages \n",
    "        else:\n",
    "            returns = torch.zeros_like(rewards).to(device)\n",
    "            for t in reversed(range(num_steps)):\n",
    "                if t == num_steps - 1:\n",
    "                    nextnonterminal = 1.0 - next_done\n",
    "                else:\n",
    "                    nextnonterminal = 1.0 - dones[t + 1]\n",
    "                    next_return = returns[t + 1]\n",
    "                returns[t] = rewards[t] + gamma * nextnonterminal * next_return\n",
    "            advantages = returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m     nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(agent_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[0;32m---> 48\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_kl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m approx_kl \u001b[38;5;241m>\u001b[39m target_kl:\n",
      "File \u001b[0;32m~/miniconda3/envs/react-rl/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/react-rl/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/react-rl/lib/python3.10/site-packages/torch/optim/adam.py:159\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    156\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     adam(\n\u001b[1;32m    169\u001b[0m         params_with_grad,\n\u001b[1;32m    170\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/react-rl/lib/python3.10/site-packages/torch/optim/adam.py:115\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    113\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "b_obs = [item for sublist in obs for item in sublist]\n",
    "b_logprobs = logprobs.reshape(-1,).to(device) # 相当于flatten为一维数组\n",
    "b_actions = actions.reshape(-1,).to(device)\n",
    "b_advantages = advantages.reshape(-1,).to(device)\n",
    "b_returns = returns.reshape(-1,).to(device)\n",
    "\n",
    "# PPO Optimizing the policy and value network\n",
    "b_inds = np.arange(batch_size) # batch_size = num_steps * num_envs\n",
    "clipfracs = []\n",
    "for epoch in tqdm(range(update_epochs)):\n",
    "    np.random.shuffle(b_inds)\n",
    "    for start in range(0, batch_size, minibatch_size):\n",
    "        end = start + minibatch_size\n",
    "        mb_inds = b_inds[start:end]\n",
    "        mb_obs = b_obs[start:end]\n",
    "        encoded_inputs = agent_tokenizer(mb_obs, padding=True, truncation=True, max_length=1024, return_tensors='pt')\n",
    "        encoded_inputs = encoded_inputs.to(device)\n",
    "        outputs = agent_model(**encoded_inputs) \n",
    "        logits = outputs.logits.squeeze(1) # 输出维度[batch_env_size, 1, prediction_size]\n",
    "        probs = Categorical(logits=logits)\n",
    "        newlogprob = probs.log_prob(b_actions[mb_inds]) # 旧动作的新logits\n",
    "        entropy = probs.entropy()\n",
    "        # _, newlogprob, entropy, newvalue = agent_model.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
    "        logratio = newlogprob - b_logprobs[mb_inds]\n",
    "        ratio = logratio.exp()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "            old_approx_kl = (-logratio).mean()\n",
    "            approx_kl = ((ratio - 1) - logratio).mean()\n",
    "            clipfracs += [((ratio - 1.0).abs() > clip_coef).float().mean().item()]\n",
    "\n",
    "        mb_advantages = b_advantages[mb_inds] # 截取minibatch\n",
    "        if norm_adv:\n",
    "            mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "        # Policy loss\n",
    "        pg_loss1 = -mb_advantages * ratio\n",
    "        pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - clip_coef, 1 + clip_coef)\n",
    "        pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "        entropy_loss = entropy.mean()\n",
    "        loss = pg_loss - ent_coef * entropy_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(agent_model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "    if target_kl is not None:\n",
    "        if approx_kl > target_kl:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/data2/lzq/mistral-7B-action-level-PPO\"\n",
    "agent_model.save_pretrained(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
